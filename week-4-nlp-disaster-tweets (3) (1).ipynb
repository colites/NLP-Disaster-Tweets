{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # graphs\nimport matplotlib.pyplot as plt # plot visualizations\nfrom sklearn.metrics import f1_score\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.metrics import Precision, Recall\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-05T15:00:36.104138Z","iopub.execute_input":"2024-03-05T15:00:36.104574Z","iopub.status.idle":"2024-03-05T15:00:56.593064Z","shell.execute_reply.started":"2024-03-05T15:00:36.104540Z","shell.execute_reply":"2024-03-05T15:00:56.591481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Github Link :https://github.com/colites/NLP-Disaster-Tweets \n\nThe challenge problem for this project is to be able to classify disaster tweets has real or fake. The dataset has tweets that have been labeled as real or fake and the model that is going to be created must be able to effectively distinguish between both. The model that is going to be used during this project will be the RNN architecture models, such as the simpleRNN and the LSTM architectures. Their performance will be compared and the best one will be the final model. \n\nThis challenge problem requires NLP knowledge, which stands for natural language processing. Natural language processing basically is a field where machines process human language and attempt to manipulate or interpret it. This project will require NLP because the text must be processed and understood to be able to effectively classify the tweets as being real or fake. To do this, the model must be able to learn the underlying pattern in the sequences of texts, in this case the RNN will be the model that will be doing NLP to classify the tweets.\n\nTo begin this project, there must be data cleaning, which means duplicates must be dropped and empty values must be dropped from the dataframes. This is to make the data more reliable and the models train with less performance issues. Afterwards, basic EDA must be done.","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_data = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n\nprint(train_data.shape)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:00:56.595912Z","iopub.execute_input":"2024-03-05T15:00:56.596735Z","iopub.status.idle":"2024-03-05T15:00:56.690001Z","shell.execute_reply.started":"2024-03-05T15:00:56.596693Z","shell.execute_reply":"2024-03-05T15:00:56.688495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['word_count']=train_data['text'].apply(lambda x: len(x.split()))\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:00:56.691994Z","iopub.execute_input":"2024-03-05T15:00:56.692471Z","iopub.status.idle":"2024-03-05T15:00:56.722257Z","shell.execute_reply.started":"2024-03-05T15:00:56.692438Z","shell.execute_reply":"2024-03-05T15:00:56.720878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#find the number of duplicates in the training data\nduplicates = train_data['text'].duplicated().sum()\nprint(duplicates)\n\nvalue_counts_df = train_data['target'].value_counts().reset_index()\nvalue_counts_df.columns = ['target', 'count']\n\nax = sns.barplot(x='target', y='count', data=value_counts_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:00:56.724894Z","iopub.execute_input":"2024-03-05T15:00:56.725354Z","iopub.status.idle":"2024-03-05T15:00:56.992447Z","shell.execute_reply.started":"2024-03-05T15:00:56.725320Z","shell.execute_reply":"2024-03-05T15:00:56.990038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_count = train_data.isnull().sum()\nprint(f' The number of missing values is :{missing_values_count}')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:00:56.996661Z","iopub.execute_input":"2024-03-05T15:00:56.997088Z","iopub.status.idle":"2024-03-05T15:00:57.010243Z","shell.execute_reply.started":"2024-03-05T15:00:56.997057Z","shell.execute_reply":"2024-03-05T15:00:57.009011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will drop the keyword and location columns because they contain empty values and we are not going to be using those columns, so dropping them will solve the problem of null values.","metadata":{}},{"cell_type":"code","source":"train_data.drop(['keyword', 'location'], axis=1, inplace=True)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:04:02.301798Z","iopub.execute_input":"2024-03-05T15:04:02.302212Z","iopub.status.idle":"2024-03-05T15:04:02.316667Z","shell.execute_reply.started":"2024-03-05T15:04:02.302180Z","shell.execute_reply":"2024-03-05T15:04:02.315481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.drop_duplicates(subset='text')\nduplicates = train_data['text'].duplicated().sum()\nprint(duplicates)\n\nvalue_counts_df = train_data['target'].value_counts().reset_index()\nvalue_counts_df.columns = ['target', 'count']\n\nax = sns.barplot(x='target', y='count', data=value_counts_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:04:06.770075Z","iopub.execute_input":"2024-03-05T15:04:06.770497Z","iopub.status.idle":"2024-03-05T15:04:06.928947Z","shell.execute_reply.started":"2024-03-05T15:04:06.770463Z","shell.execute_reply":"2024-03-05T15:04:06.927670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## a plot to get the ranges for word count in the text data\nax2 = sns.boxplot(x='target', y='word_count', data=train_data)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:04:13.523601Z","iopub.execute_input":"2024-03-05T15:04:13.524005Z","iopub.status.idle":"2024-03-05T15:04:13.708594Z","shell.execute_reply.started":"2024-03-05T15:04:13.523975Z","shell.execute_reply":"2024-03-05T15:04:13.707461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = train_data['target']\ntrain_features = train_data['text']\n\ntest_features = test_data['text']\n\nprint(\"test features shape: \", test_features.shape)\nprint(\"test features type: \", test_features.dtype)\nprint(\"train features shape: \", train_features.shape)\nprint(\"train labels shape: \", train_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:04:16.732312Z","iopub.execute_input":"2024-03-05T15:04:16.733087Z","iopub.status.idle":"2024-03-05T15:04:16.741035Z","shell.execute_reply.started":"2024-03-05T15:04:16.733054Z","shell.execute_reply":"2024-03-05T15:04:16.739609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## This snippet tokenizes the texts by creating a dictionary of a word to an numerical id. Then this is turned into a sequence of integers. The RNN structure only takes in a certain length sequence, so a length is set\n## and anything that is shorter is padded with 0's while anything longer has the extra integers removed.\ntokenizer = Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(train_features) \n\n# Convert the text to sequences of integers\nsequences = tokenizer.texts_to_sequences(train_features)\ntest_sequences = tokenizer.texts_to_sequences(test_features)\n\npadded_sequences = pad_sequences(sequences, maxlen=100, padding='post')\npadded_test_sequences = pad_sequences(test_sequences, maxlen=100, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:04:18.620200Z","iopub.execute_input":"2024-03-05T15:04:18.620857Z","iopub.status.idle":"2024-03-05T15:04:19.141733Z","shell.execute_reply.started":"2024-03-05T15:04:18.620823Z","shell.execute_reply":"2024-03-05T15:04:19.140580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Modularized function to graph a metric based on the fitted model's history\ndef plot_metrics_graph(metric, x_label, title):\n    plt.plot(metric)\n    plt.title(title)\n    plt.ylabel(x_label)\n    plt.xlabel('Epoch')\n    plt.legend(['Train'], loc='upper left')\n    plt.show()\n    \n## Function to create a submission csv\ndef submit_csv(name, test_pred):\n    submission = test_data.rename(columns={'text': 'target'})\n    if 'keyword' in submission.columns and 'location' in submission.columns:\n        submission.drop(['keyword', 'location'], axis=1, inplace=True)\n    submission['target'] = test_pred\n    submission.to_csv(name, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:04:25.291014Z","iopub.execute_input":"2024-03-05T15:04:25.291415Z","iopub.status.idle":"2024-03-05T15:04:25.300280Z","shell.execute_reply.started":"2024-03-05T15:04:25.291371Z","shell.execute_reply":"2024-03-05T15:04:25.298867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first architecture I am going to explore will be the RNN architecture. This is the simplest of the sequential neural network models, with more advanced models like LSTM being used later for comparison.\n\nThe first layer is an embedding layer that transforms each token into a dense vector. This layer also decides the characteristics of the sequence vectors that will be analyzed by the RNN layer. For the first architecture, the vector dimensions will be 128 and the length of the sequence vectors will all be 100. The sequences were padded during preprocessing previously to be of length 100 and the output vectors will be the same length.\n\nThe RNN layer is made up of 64 neurons. 64 neurons were chosen for this RNN architecture because it is a commonly used number of neurons due to it being a moderate position, with the choice to be able to reduce the number of neurons if there is overfitting or increase the number of neurons if there is underfitting. The simpleRNN layer takes care of the hidden state updates for all the RNN Neurons in the layer. There will be 1 RNN layer to be able to see the effects of neurons in a layer, but it is possible to have multiple RNN layers. Having 1 layer may result in underfitting, but this first architecture will test the number of neurons in a layer more than the number of layers.\n\nThe last dense layer is the classification layer with a sigmoid activation. This is the layer that actually returns the binary probability. This layer has one neuron because this is a binary classification task and it gets the information from the RNN layer. The probability of the sequence is calculated by the sigmoid activation function, which outputs a probability score between 0 and 1. This score can then used to classify to one of the target labels. \n\nThe procedure to optimize hyperparameters is to just start out with common defaults and then change directions based on how the model does. For example, if a model overfits then I would tune the hyperparameters to regularize more or tune the hyperparameters to reduce the complexity of the model and therefore reduce the overfitting. If there is underfitting, when the model does not get good training metrics, then more complexity by tuning the hyperparameters will happen. In this case, one example is when I tuned neurons and reduced or increased them based on how well the models performed. ","metadata":{}},{"cell_type":"code","source":"def RNN_simple():\n    model = Sequential([\n                Embedding(input_dim=10000 , output_dim=128, input_length=100),\n                SimpleRNN(units=64, return_sequences=False),\n                Dense(units=1, activation='sigmoid')\n            ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:00:58.016034Z","iopub.execute_input":"2024-03-05T15:00:58.016509Z","iopub.status.idle":"2024-03-05T15:00:58.030881Z","shell.execute_reply.started":"2024-03-05T15:00:58.016467Z","shell.execute_reply":"2024-03-05T15:00:58.029319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_simple_RNN = RNN_simple()\nmodel_simple_RNN.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n\nhistory_simple_RNN = model_simple_RNN.fit(padded_sequences, train_labels, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:00:58.032833Z","iopub.execute_input":"2024-03-05T15:00:58.033497Z","iopub.status.idle":"2024-03-05T15:03:22.183561Z","shell.execute_reply.started":"2024-03-05T15:00:58.033435Z","shell.execute_reply":"2024-03-05T15:03:22.182498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The competition is being evaluated using F1-score, so the F1-score must be calculated to effectively measure how the model is doing for the competition\n\nThe F1-score is (2 * Precision * Recall)/ (Precision + Recall). The F1-score basically represents a balance between precision and recall. Since Keras does not have a F1-score function that can be measured each epoch, then it must be calculated manually after the model is fitted.\n\nThis means that the Precision and Recall must be kept track of to be able to do the final F1-score calculation. The accuracy will also be tracked as well as the loss. ","metadata":{}},{"cell_type":"code","source":"## function that does an prediction using the chosen model architecture\ndef model_predict(model, padded_sequences):\n    ## Model outputs probabilities for the True label, must be made into binary predictions\n    y_pred_prob = model.predict(padded_sequences)\n    y_pred = np.where(y_pred_prob > 0.5, 1, 0)\n    y_pred = y_pred.flatten()\n    \n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:03:22.185247Z","iopub.execute_input":"2024-03-05T15:03:22.185751Z","iopub.status.idle":"2024-03-05T15:03:22.193463Z","shell.execute_reply.started":"2024-03-05T15:03:22.185707Z","shell.execute_reply":"2024-03-05T15:03:22.191899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_simple_RNN, padded_sequences)\nf1 = f1_score(train_labels, y_pred)\nprint(f'this is the final f1-score for the train set: {f1}')\nplot_metrics_graph(history_simple_RNN.history['accuracy'], 'Accuracy', 'Model Accuracy over Epochs')\nplot_metrics_graph(history_simple_RNN.history['precision'], 'Precision', 'Precision over Epochs')\nplot_metrics_graph(history_simple_RNN.history['recall'], 'Recall', 'Recall over Epochs')\nplot_metrics_graph(history_simple_RNN.history['loss'], 'Loss', 'Model Loss over Epochs')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:03:22.199901Z","iopub.execute_input":"2024-03-05T15:03:22.200712Z","iopub.status.idle":"2024-03-05T15:03:25.712298Z","shell.execute_reply.started":"2024-03-05T15:03:22.200663Z","shell.execute_reply":"2024-03-05T15:03:25.710685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_simple_RNN, padded_test_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:03:25.714083Z","iopub.execute_input":"2024-03-05T15:03:25.714581Z","iopub.status.idle":"2024-03-05T15:03:26.646314Z","shell.execute_reply.started":"2024-03-05T15:03:25.714540Z","shell.execute_reply":"2024-03-05T15:03:26.645405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv('simple.csv', y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:03:26.649621Z","iopub.execute_input":"2024-03-05T15:03:26.650100Z","iopub.status.idle":"2024-03-05T15:03:26.665101Z","shell.execute_reply.started":"2024-03-05T15:03:26.650063Z","shell.execute_reply":"2024-03-05T15:03:26.663922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The One layer RNN does very well depending on the initialization. The precision and recall heavily depend on initial weights, since fitting the one layer RNN multiple times led to some 0.0  training f1 scores. some training 0.91 f1 scores, and the 0.74 f1 score that was the final fitting of the model. It seems that in the final fitting of the simple RNN architecture with one layer, the precision and recall were maximized in teh 6th epoch. If the models continue to maximize at lower epochs, the training epochs may be reduced to prevent reduction of precision and recall. The final test f1 score was 0.654 for the first simple model\n\nWe can try out a two-layer RNN to see whether the f1-score will increase slightly, due to possible capturing more complex patterns in the data. There is a strong possibility that the data from the two-layer RNN will overfit due to the model becoming too complex and learning the training dataset, since the one-layer model already did very well occasionally in the training dataset. There is also a possibility that instead of overfitting and getting a better score for the training set, the two-layer model may get a worse f1-score due to having more noise be registered by the model due to its increased complexity. The model may try to learn complex details that are ultimately unhelpful and detrimental to classifing, which would decrease the f1-score. \n\nSince the two-layer RNN is more complex and can learn more complex interactions, the neurons for the second layer were reduced to 32 because there is already a large chance of overfitting with the addition of a second layer, so lowering the neurons in the second layer serves as a balance to reduce the chances of overfitting and also reduce the chances of a drastic decrease in the f1-score due to noise in the data making the model learn incorrect information.","metadata":{}},{"cell_type":"code","source":"def RNN_two():\n    model = Sequential([\n                Embedding(input_dim=10000 , output_dim=128, input_length=100),\n                SimpleRNN(units=64, return_sequences=True),\n                SimpleRNN(units=32, return_sequences=False),\n                Dense(units=1, activation='sigmoid')\n            ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:03:26.666697Z","iopub.execute_input":"2024-03-05T15:03:26.667304Z","iopub.status.idle":"2024-03-05T15:03:26.672451Z","shell.execute_reply.started":"2024-03-05T15:03:26.667270Z","shell.execute_reply":"2024-03-05T15:03:26.671495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_two_RNN = RNN_two()\nmodel_two_RNN.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n\nhistory_two_RNN = model_two_RNN.fit(padded_sequences, train_labels, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:05:11.905040Z","iopub.execute_input":"2024-03-05T15:05:11.905504Z","iopub.status.idle":"2024-03-05T15:07:14.609651Z","shell.execute_reply.started":"2024-03-05T15:05:11.905468Z","shell.execute_reply":"2024-03-05T15:07:14.608513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_two_RNN, padded_sequences)\nf1 = f1_score(train_labels, y_pred)\nprint(f'this is the final f1-score for the train set: {f1}')\nplot_metrics_graph(history_two_RNN.history['accuracy'], 'Accuracy', 'Model Accuracy over Epochs')\nplot_metrics_graph(history_two_RNN.history['precision'], 'Precision', 'Precision over Epochs')\nplot_metrics_graph(history_two_RNN.history['recall'], 'Recall', 'Recall over Epochs')\nplot_metrics_graph(history_two_RNN.history['loss'], 'Loss', 'Model Loss over Epochs')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:07:14.612504Z","iopub.execute_input":"2024-03-05T15:07:14.612995Z","iopub.status.idle":"2024-03-05T15:07:18.679435Z","shell.execute_reply.started":"2024-03-05T15:07:14.612950Z","shell.execute_reply":"2024-03-05T15:07:18.678403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_two_RNN, padded_test_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:07:18.680508Z","iopub.execute_input":"2024-03-05T15:07:18.680871Z","iopub.status.idle":"2024-03-05T15:07:20.086241Z","shell.execute_reply.started":"2024-03-05T15:07:18.680840Z","shell.execute_reply":"2024-03-05T15:07:20.085214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv('two.csv', y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:07:20.088832Z","iopub.execute_input":"2024-03-05T15:07:20.089255Z","iopub.status.idle":"2024-03-05T15:07:20.101172Z","shell.execute_reply.started":"2024-03-05T15:07:20.089221Z","shell.execute_reply":"2024-03-05T15:07:20.099880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen, the F1-score was better in the two-layered RNN for the training set, but slightly worse in the test set with a 0.621 f1 score. What is very important information is to see that the two-layered RNN had a greater than 20% f1 score difference between testing and training f1-scores, meaning that it is overfitting. The highest precision and recall scores for training were past the 6th epoch, which means it is worth keeping the 10 epochs for every model. When fitting this model multiple times, the loss exploded upwards significantly in some runs. This means that the two-layered model had a problem, possibly related to exploding gradients. RNN's are susceptible to occurences of the vanishing/exploding gradient and they are characterized by a sudden spike in the loss.\n\nNow, we will be testing an LSTM architecture instead of a RNN architecture. Since the two-layered RNN performed slightly worse than the one-layered RNN, the LSTM will be one layered because LSTM can retain more information due to the greatly increased complexity of its structure. The LSTM mitigates the issue of the exploding gradient, so the issue is not as prevalent in a LSTM layer compared to a standard RNN layer. The LSTM model will also have less neurons than the simple one layer RNN, to prevent overfitting.","metadata":{}},{"cell_type":"code","source":"def LSTM_model():\n    model = Sequential([\n                Embedding(input_dim=10000, output_dim=128, input_length=100),\n                LSTM(units=32, return_sequences=False),  \n                Dense(units=1, activation='sigmoid')\n            ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:07:20.103494Z","iopub.execute_input":"2024-03-05T15:07:20.103881Z","iopub.status.idle":"2024-03-05T15:07:20.109403Z","shell.execute_reply.started":"2024-03-05T15:07:20.103849Z","shell.execute_reply":"2024-03-05T15:07:20.108322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_LSTM = LSTM_model()\nmodel_LSTM.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n\nhistory_LSTM = model_LSTM.fit(padded_sequences, train_labels, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:07:20.111486Z","iopub.execute_input":"2024-03-05T15:07:20.112182Z","iopub.status.idle":"2024-03-05T15:09:44.809811Z","shell.execute_reply.started":"2024-03-05T15:07:20.112117Z","shell.execute_reply":"2024-03-05T15:09:44.808820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_LSTM, padded_sequences)\nf1 = f1_score(train_labels, y_pred)\nprint(f'this is the final f1-score for the train set: {f1}')\nplot_metrics_graph(history_LSTM.history['accuracy'], 'Accuracy', 'Model Accuracy over Epochs')\nplot_metrics_graph(history_LSTM.history['precision'], 'Precision', 'Precision over Epochs')\nplot_metrics_graph(history_LSTM.history['recall'], 'Recall', 'Recall over Epochs')\nplot_metrics_graph(history_LSTM.history['loss'], 'Loss', 'Model Loss over Epochs')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:09:44.811348Z","iopub.execute_input":"2024-03-05T15:09:44.811919Z","iopub.status.idle":"2024-03-05T15:09:48.634425Z","shell.execute_reply.started":"2024-03-05T15:09:44.811888Z","shell.execute_reply":"2024-03-05T15:09:48.633325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen above, the LSTM model is not learning and gets a 0 f1-score with a 57% accuracy, which almost corresponds to the length of labels in the majority class. This means that the LSTM model is probably only predicting the majority class. Simple RNN performs well on shorter sequences where long term knowledge is less important. In the simple RNN models, a maxlen of 100 was designated, meaning many sequences had large amounts of padding. LSTM is more sensitive to padding, since its strength of learning long term dependencies relies on gates that will be more busy handling the non-informative padding, losing important long term information that leads to worsening predictions. This time, I will reduce the padding significantly. The biggest sentence in the texts has a word count above 30, which means padding of 100 adds lots of zeroes as padding. This time, the maxlen will be 36, which means that most sequences will have only a little padding and LSTM can more effectively gain knowledge. ","metadata":{}},{"cell_type":"code","source":"## This snippet tokenizes the texts by creating a dictionary of a word to an numerical id. Then this is turned into a sequence of integers. The RNN structure only takes in a certain length sequence, so a length is set\n## and anything that is shorter is padded with 0's while anything longer has the extra integers removed.\ntokenizer = Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(train_features) \n\n# Convert the text to sequences of integers\nsequences = tokenizer.texts_to_sequences(train_features)\ntest_sequences = tokenizer.texts_to_sequences(test_features)\n\npadded_sequences = pad_sequences(sequences, maxlen=36, padding='post')\npadded_test_sequences = pad_sequences(test_sequences, maxlen=36, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:09:48.636098Z","iopub.execute_input":"2024-03-05T15:09:48.637011Z","iopub.status.idle":"2024-03-05T15:09:49.113689Z","shell.execute_reply.started":"2024-03-05T15:09:48.636977Z","shell.execute_reply":"2024-03-05T15:09:49.112492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LSTM_model():\n    model = Sequential([\n                Embedding(input_dim=10000, output_dim=128, input_length=36),\n                LSTM(units=32, return_sequences=False),  \n                Dense(units=1, activation='sigmoid')\n            ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:09:49.115201Z","iopub.execute_input":"2024-03-05T15:09:49.115954Z","iopub.status.idle":"2024-03-05T15:09:49.122026Z","shell.execute_reply.started":"2024-03-05T15:09:49.115909Z","shell.execute_reply":"2024-03-05T15:09:49.120689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_LSTM = LSTM_model()\nmodel_LSTM.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n\nhistory_LSTM = model_LSTM.fit(padded_sequences, train_labels, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:09:49.124734Z","iopub.execute_input":"2024-03-05T15:09:49.125104Z","iopub.status.idle":"2024-03-05T15:11:13.974986Z","shell.execute_reply.started":"2024-03-05T15:09:49.125073Z","shell.execute_reply":"2024-03-05T15:11:13.973859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_LSTM, padded_sequences)\nf1 = f1_score(train_labels, y_pred)\nprint(f'this is the final f1-score: {f1}')\nplot_metrics_graph(history_LSTM.history['accuracy'], 'Accuracy', 'Model Accuracy over Epochs')\nplot_metrics_graph(history_LSTM.history['precision'], 'Precision', 'Precision over Epochs')\nplot_metrics_graph(history_LSTM.history['recall'], 'Recall', 'Recall over Epochs')\nplot_metrics_graph(history_LSTM.history['loss'], 'Loss', 'Model Loss over Epochs')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:11:13.976535Z","iopub.execute_input":"2024-03-05T15:11:13.977004Z","iopub.status.idle":"2024-03-05T15:11:16.785108Z","shell.execute_reply.started":"2024-03-05T15:11:13.976846Z","shell.execute_reply":"2024-03-05T15:11:16.783699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_LSTM, padded_test_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:11:16.786911Z","iopub.execute_input":"2024-03-05T15:11:16.787429Z","iopub.status.idle":"2024-03-05T15:11:17.499641Z","shell.execute_reply.started":"2024-03-05T15:11:16.787368Z","shell.execute_reply":"2024-03-05T15:11:17.498603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv('LSTM_padding.csv', y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:11:17.501034Z","iopub.execute_input":"2024-03-05T15:11:17.501650Z","iopub.status.idle":"2024-03-05T15:11:17.511957Z","shell.execute_reply.started":"2024-03-05T15:11:17.501618Z","shell.execute_reply":"2024-03-05T15:11:17.510702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen, the padding optimization grew the LSTM f1-score from 0 to 97.4 on the train set. The test set f1-score also grew to 0.767, which means that there is overfitting but still better than the previous models seen. \n\nThis means that the padding was the issue with the LSTM learning and also serves as a potential improvement to the simple RNN architecture models, since RNN's are only more resistant to the influence of padding, not immune. Typically, models using LSTM architecture take more epochs to converge to a good score. In this case, the 10 epochs is already enough to get a high f1-score so the epochs number wil stay the same\n\nI will now test the old one layer RNN with the new padding, to see how much the new padding tuning affects the f1-score of the old one layer RNN model\n","metadata":{}},{"cell_type":"code","source":"def RNN_simple_reduced():\n    model = Sequential([\n                Embedding(input_dim=10000 , output_dim=128, input_length=36),\n                SimpleRNN(units=64, return_sequences=False),\n                Dense(units=1, activation='sigmoid')\n            ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:11:17.514272Z","iopub.execute_input":"2024-03-05T15:11:17.515159Z","iopub.status.idle":"2024-03-05T15:11:17.522209Z","shell.execute_reply.started":"2024-03-05T15:11:17.515121Z","shell.execute_reply":"2024-03-05T15:11:17.520922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_simple_RNN_reduced = RNN_simple_reduced()\nmodel_simple_RNN_reduced.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n\nhistory_simple_RNN_r = model_simple_RNN_reduced.fit(padded_sequences, train_labels, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:13:10.134037Z","iopub.execute_input":"2024-03-05T15:13:10.134495Z","iopub.status.idle":"2024-03-05T15:13:58.634640Z","shell.execute_reply.started":"2024-03-05T15:13:10.134459Z","shell.execute_reply":"2024-03-05T15:13:58.633569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_simple_RNN_reduced, padded_sequences)\nf1 = f1_score(train_labels, y_pred)\nprint(f'this is the final f1-score for the train set: {f1}')\nplot_metrics_graph(history_simple_RNN_r.history['accuracy'], 'Accuracy', 'Model Accuracy over Epochs')\nplot_metrics_graph(history_simple_RNN_r.history['precision'], 'Precision', 'Precision over Epochs')\nplot_metrics_graph(history_simple_RNN_r.history['recall'], 'Recall', 'Recall over Epochs')\nplot_metrics_graph(history_simple_RNN_r.history['loss'], 'Loss', 'Model Loss over Epochs')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:14:34.823849Z","iopub.execute_input":"2024-03-05T15:14:34.824241Z","iopub.status.idle":"2024-03-05T15:14:37.080975Z","shell.execute_reply.started":"2024-03-05T15:14:34.824212Z","shell.execute_reply":"2024-03-05T15:14:37.079619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_simple_RNN_reduced, padded_test_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:14:41.092180Z","iopub.execute_input":"2024-03-05T15:14:41.093345Z","iopub.status.idle":"2024-03-05T15:14:41.606301Z","shell.execute_reply.started":"2024-03-05T15:14:41.093307Z","shell.execute_reply":"2024-03-05T15:14:41.605463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv('RNN_padding.csv', y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:14:47.134527Z","iopub.execute_input":"2024-03-05T15:14:47.135623Z","iopub.status.idle":"2024-03-05T15:14:47.149326Z","shell.execute_reply.started":"2024-03-05T15:14:47.135568Z","shell.execute_reply":"2024-03-05T15:14:47.148173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen above, the padding tuning helped optimize the one layer RNN model too, allowing for a greater f1-score to be achieved. The train set f1-score was at 0.98 and the test set f1-score was at 0.744. While it was not better than the LSTM, it still performed well for not having the long term memory of LSTM architecture models. \n\nNext, we will try and see how well an LSTM and a RNN layer together can perform. This model will have a high risk of overfitting, due to it having two layers with large amounts of neurons, one of which is an LSTM. This model can capture long term dependencies with the LSTM layer and also provide robustness against vanishing gradients, while also being less resource intensive than two layers of LSTM.","metadata":{}},{"cell_type":"code","source":"def LSTM_two():\n    model = Sequential([\n                Embedding(input_dim=10000, output_dim=128, input_length=36),\n                LSTM(units=32, return_sequences=True),  \n                SimpleRNN(units=32, return_sequences=False),\n                Dense(units=1, activation='sigmoid')\n            ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:17:22.329926Z","iopub.execute_input":"2024-03-05T15:17:22.330358Z","iopub.status.idle":"2024-03-05T15:17:22.336319Z","shell.execute_reply.started":"2024-03-05T15:17:22.330324Z","shell.execute_reply":"2024-03-05T15:17:22.335282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_LSTM_two = LSTM_two()\nmodel_LSTM_two.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n\nhistory_LSTM_two = model_LSTM_two.fit(padded_sequences, train_labels, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:17:24.736603Z","iopub.execute_input":"2024-03-05T15:17:24.737184Z","iopub.status.idle":"2024-03-05T15:18:47.383107Z","shell.execute_reply.started":"2024-03-05T15:17:24.737153Z","shell.execute_reply":"2024-03-05T15:18:47.382169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_LSTM_two, padded_sequences)\nf1 = f1_score(train_labels, y_pred)\nprint(f'this is the final f1-score: {f1}')\nplot_metrics_graph(history_LSTM_two.history['accuracy'], 'Accuracy', 'Model Accuracy over Epochs')\nplot_metrics_graph(history_LSTM_two.history['precision'], 'Precision', 'Precision over Epochs')\nplot_metrics_graph(history_LSTM_two.history['recall'], 'Recall', 'Recall over Epochs')\nplot_metrics_graph(history_LSTM_two.history['loss'], 'Loss', 'Model Loss over Epochs')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:18:47.384892Z","iopub.execute_input":"2024-03-05T15:18:47.385967Z","iopub.status.idle":"2024-03-05T15:18:50.526723Z","shell.execute_reply.started":"2024-03-05T15:18:47.385931Z","shell.execute_reply":"2024-03-05T15:18:50.525579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_predict(model_LSTM_two, padded_test_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:18:50.528281Z","iopub.execute_input":"2024-03-05T15:18:50.529329Z","iopub.status.idle":"2024-03-05T15:18:51.363319Z","shell.execute_reply.started":"2024-03-05T15:18:50.529282Z","shell.execute_reply":"2024-03-05T15:18:51.362449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_csv('LSTM_RNN_comb.csv', y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T15:18:51.364990Z","iopub.execute_input":"2024-03-05T15:18:51.365899Z","iopub.status.idle":"2024-03-05T15:18:51.376371Z","shell.execute_reply.started":"2024-03-05T15:18:51.365866Z","shell.execute_reply":"2024-03-05T15:18:51.375399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The LSTM and simpleRNN model tied in the test set with the single LSTM with padding model, gaining a 0.76 test set f1-score. This result makes sense, since the problem with the previous models was overfitting of the model, with high training f1-scores and lower test f1-scores. This model did not address these deficiencies, since it still had two layers with a high amount of neurons in each layer.","metadata":{}},{"cell_type":"markdown","source":"                                                                                            **CONCLUSION**","metadata":{}},{"cell_type":"markdown","source":"| Model | Training f1      | Test f1 |\n|----|-----------|-----|\n| Simple  | 0.79     | 0.65  |\n| Two layer RNN  | 0.93      | 0.62  |\n| LSTM, pre-padding change | 0.0   | 0  |\n| LSTM, post padding change |0.97 | 0.76  |\n| Simple post padding | 0.98 | 0.74 |\n| LSTM and simpleRNN combined | 0.97 | 0.76  |","metadata":{}},{"cell_type":"markdown","source":"As can be seen in the table above, the best model was the one layer LSTM after the padding change. It had the highest test f1-score at 0.76. It seems that the slightly more complex architectures, the ones with LSTM layers, did better than the other models slightly. This is probably due to their longer memory. It did not do much better though and seems to be overfitting, which means techniques like early stopping would be necessary, perhaps reducing neurons in the layers slightly would also increase the generalization of the model.\n\nOverall the biggest lesson learned was to pre-process the dataset well because I had not put thought into the padding and the padding was what was bringing down the test accuracy in all the models. The big improvements came from changing the padding, with the bad padding only being visible due to how bad the first LSTM model performed. \n\nMaking the architecture a little more complex did help increase the f1-score very slightly, since the LSTM models had the best f1-scores by 2%. There was overfitting of the data since the training set f1-scores were much higher than the test f1-scores. To resolve this in the future, I should add validation sets and then implement early stopping whenever the validation scores lower in an epoch. This would help with stopping overfitting if it happens in the later epochs, and the validation set would also help spot the overfitting sooner rather than being surprised during the submission of the testing data. Trying other architectures like bi-directional RNN's might increase f1-scores too, so it is something to do for next time.","metadata":{}},{"cell_type":"markdown","source":"This link helped explain f1-score to me:\nhttps://www.v7labs.com/blog/f1-score-guide","metadata":{}}]}